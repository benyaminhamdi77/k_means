import numpy as np

# تابع محاسبه فاصله اقلیدسی
def euclidean_distance(p1, p2):
    return np.sqrt(np.sum((p1 - p2) ** 2))

# تابع محاسبه فاصله منهتن
def manhattan_distance(p1, p2):
    return np.sum(np.abs(p1 - p2))

# تابع خوشه‌بندی K-Means بدون استفاده از کتابخانه
def kmeans(X, k, distance_type='euclidean', max_iters=100):
    # 1. انتخاب تصادفی k مرکز اولیه از مختصات بین -10 و 10
    centroids = np.random.uniform(low=-10, high=10, size=(k, X.shape[1]))
    
    for _ in range(max_iters):
        # 2. اختصاص نقاط به نزدیک‌ترین مرکز
        clusters = [[] for _ in range(k)]
        for point in X:
            if distance_type == 'euclidean':
                distances = [euclidean_distance(point, centroid) for centroid in centroids]
            elif distance_type == 'manhattan':
                distances = [manhattan_distance(point, centroid) for centroid in centroids]
            else:
                raise ValueError("روش فاصله‌گذاری اشتباه است. باید 'euclidean' یا 'manhattan' باشد.")
            
            closest_centroid = np.argmin(distances)
            clusters[closest_centroid].append(point)
        
        # 3. محاسبه مراکز جدید هر خوشه
        new_centroids = np.array([np.mean(cluster, axis=0) if cluster else centroids[i] 
                                  for i, cluster in enumerate(clusters)])
        
        # 4. بررسی همگرایی: اگر مراکز تغییر نکنند، الگوریتم تمام می‌شود
        if np.all(centroids == new_centroids):
            break
        centroids = new_centroids
    
    # برگرداندن نتایج نهایی
    return centroids, clusters

# دریافت ورودی از کاربر
k = int(input(" enter k / tedad khoshe"))
distance_type = input("enter calculate (euclidean / manhattan): ")

# 1 وارد کردن داده‌
data =np.array([[9.84, -4.76, -8.57],
    [9.22, 7.58, 0.2],
    [0.68, 0.8, 1.36],
    [4.3, -0.68, -6.25],
    [-9.49, -5.19, -7.91],
    [-8.0, -1.6, 5.39],
    [5.13, -8.54, -6.69],
    [8.58, -8.13, 9.36],
    [7.27, 4.89, 6.23],
    [3.09, 1.8, 3.99],
    [-1.19, 1.06, 2.32],
    [2.09, 8.88, 4.37],
    [-4.64, 0.79, -2.26],
    [9.43, -9.89, 5.11],
    [0.14, 1.0, -4.79],
    [1.09, -4.11, 4.22],
    [4.96, -8.56, -2.65],
    [9.23, -0.61, -7.67],
    [9.12, 9.62, 0.04],
    [-2.07, 5.4, 3.92],
    [0.52, -0.09, 5.8],
    [3.59, 4.99, -0.62],
    [4.73, -5.16, 0.18],
    [6.54, 3.51, 1.25],
    [4.05, 4.27, -4.05],
    [3.91, 1.42, -8.46],
    [-3.0, -2.43, -9.9],
    [8.04, 2.95, -6.72],
    [9.35, -7.19, -8.37],
    [-9.7, -4.77, 8.37],
    [-4.67, 2.35, -3.29],
    [-4.56, 2.4, 9.44],
    [9.21, 3.56, 8.09],
    [1.92, -5.96, 9.45],
    [0.44, -8.79, -4.27],
    [-2.78, 9.33, -5.96],
    [6.57, -4.5, -3.88],
    [7.74, 2.98, 4.65],
    [-6.02, 6.25, 0.89],
    [-4.33, -0.45, -1.49],
    [-8.92, -8.1, 0.89],
    [3.54, 2.49, -7.09],
    [-6.5, 9.77, -3.37],
    [-4.92, 8.66, 4.18],
    [-2.54, -1.14, 3.29],
    [-2.9, 0.63, 5.35],
    [-9.8, -2.69, -5.38],
    [6.13, 5.35, -9.66],
    [4.32, 2.77, -2.76],
    [-4.87, 3.61, 0.21],
    [-8.63, 7.06, -7.89],
    [-9.36, 8.22, 0.89],
    [-2.45, 0.05, -6.25],
    [-2.4, 5.58, 2.57],
    [-0.25, -0.92, 5.51],
    [-8.62, 8.46, -4.76],
    [-5.49, -8.81, -2.39],
    [7.77, -9.13, -4.28],
    [4.96, -6.27, -7.33],
    [-8.53, 3.78, -7.14],
    [0.39, 5.1, -8.3],
    [-3.27, -0.72, -6.44],
    [1.32, 9.55, 4.58],
    [8.91, -8.68, 1.88],
    [-1.38, 5.13, -2.54],
    [6.66, 5.62, 8.78],
    [7.79, 3.86, 6.01],
    [9.16, -3.0, -1.79],
    [-3.23, -9.2, -4.9],
    [2.87, -3.04, -3.46],
    [9.28, -3.03, 6.34],
    [9.65, -6.92, -0.26],
    [-6.06, 8.06, -5.26],
    [9.06, 1.78, -9.04],
    [-0.78, -8.9, 6.64],
    [-7.36, -2.39, -8.25],
    [-5.09, 8.22, 2.0],
    [4.2, 1.01, -2.44],
    [7.7, 4.6, -7.96],
    [0.81, -8.31, 9.04],
    [9.59, -5.98, -4.92],
    [-9.83, -8.3, -5.09],
    [-7.65, 4.76, -6.71],
    [-1.11, -0.52, -5.27]]) 


# 2. اجرای الگوریتم K-Means
centroids, clusters = kmeans(data, k, distance_type)

# 3. نمایش نتایج
for i , cluster in enumerate(clusters):
    print(f"khoshe {i+1}:")
    print(np.array(cluster))
    print(f"khoshe center {centroids[i]}")
    
